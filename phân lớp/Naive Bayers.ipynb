{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44aff305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a905f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class NaiveBayes:\n",
    "    def fit(self, X, y):#X:data y:label\n",
    "        n_samples, n_features = X.shape#number of row is n_samples, number of column is n_feature\n",
    "        self._classes = np.unique(y)#_class conclude unquie of y\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        # calculate mean, var, and prior for each class\n",
    "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64) #tao ma tran 0 2 chieu chua mean\n",
    "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)#tao ma tran 0 2 chieu chua var\n",
    "        self._priors = np.zeros(n_classes, dtype=np.float64)#tao ma tran 0 1 chieu chua prior\n",
    "\n",
    "        for idx, c in enumerate(self._classes):\n",
    "            X_c = X[y == c] #mean each class, i_row and each(all) column\n",
    "            self._mean[idx, :] = X_c.mean(axis=0)\n",
    "            self._var[idx, :] = X_c.var(axis=0)#var each class, i_row and each(all) column\n",
    "            self._priors[idx] = X_c.shape[0] / float(n_samples)#prior this class, X_i.shape[0]: number of this class, diveded with number of total samples\n",
    "\n",
    "    def predict(self, X):#def predict doan label tu mau test\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        \n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):#apply function y = argmaxXi Log(P(xi/y)) +... Log(P(y))\n",
    "        posteriors = []\n",
    "\n",
    "        # calculate posterior probability for each class\n",
    "        for idx, c in enumerate(self._classes):\n",
    "            prior = np.log(self._priors[idx])\n",
    "            posterior = np.sum(np.log(self._pdf(idx, x)))\n",
    "            posterior = prior + posterior\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        # return class with highest posterior probability\n",
    "        return self._classes[np.argmax(posteriors)] #tra ve label duoc phan loai\n",
    "\n",
    "    def _pdf(self, class_idx, x):#apply formula P(xi/y) = 1/sqrt(2pi*var) * exp(- (xi-y)**2/ 2var)\n",
    "        mean = self._mean[class_idx]\n",
    "        var = self._var[class_idx]\n",
    "        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39e2b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9366666666666666\n"
     ]
    }
   ],
   "source": [
    "#scikit-learn datasets make_classification\n",
    "X, y = datasets.make_classification(n_samples = 1000, n_features = 10, n_classes = 2, random_state = 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 70)\n",
    "\n",
    "nb = NaiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "pre = nb.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb28634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#scikit-learn datasets Iris\n",
    "df = datasets.load_iris()\n",
    "A= df.data\n",
    "b = df.target\n",
    "A_train, A_test, b_train, b_test = train_test_split(A,b, test_size = 0.25, random_state = 40)\n",
    "\n",
    "nb2 = NaiveBayes()\n",
    "nb2.fit(A_train, b_train)\n",
    "pre2 = nb2.predict(A_test)\n",
    "\n",
    "print(accuracy_score(b_test, pre2))\n",
    "#print(A_test, pre2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ddb251b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category                                            Message  Spam\n",
      "0      ham  Go until jurong point, crazy.. Available only ...     0\n",
      "1      ham                      Ok lar... Joking wif u oni...     0\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
      "3      ham  U dun say so early hor... U c already then say...     0\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...     0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Ví dụ thứ 2, sử dụng dataset pandas .csv, sử dụng Multinomial Classifier của thư viện sklearn.naive_bayes với mục tiêu phân loại\n",
    "đâu là email spam = spam và đâu là email not spam = ham '''\n",
    "import pandas as pd\n",
    "from  sklearn.naive_bayes import MultinomialNB as NB\n",
    "#them class 0 1 cho data\n",
    "dataset = pd.read_csv('spam.csv')\n",
    "dataset['Spam'] = dataset['Category'].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "print(dataset.head())\n",
    "\n",
    "#chia class va features\n",
    "X1 = dataset['Message']\n",
    "y1 = dataset['Spam']\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2)\n",
    "\n",
    "#dua text trong X ve du lieu number\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer()\n",
    "X_train_count = v.fit_transform(X1_train)\n",
    "X_train_count.toarray()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "def90522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838565022421525"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_count,y1_train)\n",
    "#test with 2 feature\n",
    "emails = [\n",
    "    'Hey mohan, can we get together to watch footbal game tomorrow?',\n",
    "    'Upto 20% discount on parking, exclusive offer just for you. Dont miss this reward!'\n",
    "]\n",
    "emails_count = v.transform(emails)\n",
    "model.predict(emails_count)\n",
    "\n",
    "#evalu accuracy\n",
    "X_test_count = v.transform(X1_test)\n",
    "model.score(X_test_count, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0bd8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
